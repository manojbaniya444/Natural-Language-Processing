{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\acer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\acer/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\acer/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\acer/nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mero', 'iPhone', '13', 'Rs', '90,000', 'ma', 'cha', '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Mero iPhone 13 Rs 90,000 ma cha.\"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mero', 'NNP'),\n",
       " ('iPhone', 'NN'),\n",
       " ('13', 'CD'),\n",
       " ('Rs', 'NNP'),\n",
       " ('90,000', 'CD'),\n",
       " ('ma', 'NN'),\n",
       " ('cha', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = ne_chunk(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,344.0,168.0\" width=\"344px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"13.9535%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Mero</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.97674%\" y1=\"20px\" y2=\"48px\" /><svg width=\"18.6047%\" x=\"13.9535%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">iPhone</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.2558%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.30233%\" x=\"32.5581%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">13</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.2093%\" y1=\"20px\" y2=\"48px\" /><svg width=\"11.6279%\" x=\"41.8605%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Rs</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.6744%\" y1=\"20px\" y2=\"48px\" /><svg width=\"18.6047%\" x=\"53.4884%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">90,000</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.7907%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.30233%\" x=\"72.093%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ma</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.7442%\" y1=\"20px\" y2=\"48px\" /><svg width=\"11.6279%\" x=\"81.3953%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">cha</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.2093%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.97674%\" x=\"93.0233%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.5116%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('GPE', [('Mero', 'NNP')]), ('iPhone', 'NN'), ('13', 'CD'), ('Rs', 'NNP'), ('90,000', 'CD'), ('ma', 'NN'), ('cha', 'NN'), ('.', '.')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.79176        0.429\n",
      "             2          -0.76557        1.000\n",
      "             3          -0.49475        1.000\n",
      "             4          -0.36451        1.000\n",
      "             5          -0.28836        1.000\n",
      "             6          -0.23847        1.000\n",
      "             7          -0.20329        1.000\n",
      "             8          -0.17715        1.000\n",
      "             9          -0.15697        1.000\n",
      "            10          -0.14093        1.000\n",
      "            11          -0.12786        1.000\n",
      "            12          -0.11702        1.000\n",
      "            13          -0.10788        1.000\n",
      "            14          -0.10006        1.000\n",
      "            15          -0.09331        1.000\n",
      "            16          -0.08741        1.000\n",
      "            17          -0.08221        1.000\n",
      "            18          -0.07760        1.000\n",
      "            19          -0.07348        1.000\n",
      "            20          -0.06978        1.000\n",
      "            21          -0.06644        1.000\n",
      "            22          -0.06340        1.000\n",
      "            23          -0.06063        1.000\n",
      "            24          -0.05809        1.000\n",
      "            25          -0.05576        1.000\n",
      "            26          -0.05360        1.000\n",
      "            27          -0.05161        1.000\n",
      "            28          -0.04976        1.000\n",
      "            29          -0.04804        1.000\n",
      "            30          -0.04644        1.000\n",
      "            31          -0.04494        1.000\n",
      "            32          -0.04353        1.000\n",
      "            33          -0.04221        1.000\n",
      "            34          -0.04097        1.000\n",
      "            35          -0.03980        1.000\n",
      "            36          -0.03870        1.000\n",
      "            37          -0.03765        1.000\n",
      "            38          -0.03666        1.000\n",
      "            39          -0.03572        1.000\n",
      "            40          -0.03483        1.000\n",
      "            41          -0.03398        1.000\n",
      "            42          -0.03317        1.000\n",
      "            43          -0.03240        1.000\n",
      "            44          -0.03167        1.000\n",
      "            45          -0.03096        1.000\n",
      "            46          -0.03029        1.000\n",
      "            47          -0.02965        1.000\n",
      "            48          -0.02903        1.000\n",
      "            49          -0.02844        1.000\n",
      "            50          -0.02788        1.000\n",
      "            51          -0.02733        1.000\n",
      "            52          -0.02681        1.000\n",
      "            53          -0.02630        1.000\n",
      "            54          -0.02582        1.000\n",
      "            55          -0.02535        1.000\n",
      "            56          -0.02490        1.000\n",
      "            57          -0.02446        1.000\n",
      "            58          -0.02404        1.000\n",
      "            59          -0.02364        1.000\n",
      "            60          -0.02325        1.000\n",
      "            61          -0.02287        1.000\n",
      "            62          -0.02250        1.000\n",
      "            63          -0.02214        1.000\n",
      "            64          -0.02180        1.000\n",
      "            65          -0.02146        1.000\n",
      "            66          -0.02114        1.000\n",
      "            67          -0.02083        1.000\n",
      "            68          -0.02052        1.000\n",
      "            69          -0.02023        1.000\n",
      "            70          -0.01994        1.000\n",
      "            71          -0.01966        1.000\n",
      "            72          -0.01939        1.000\n",
      "            73          -0.01912        1.000\n",
      "            74          -0.01887        1.000\n",
      "            75          -0.01862        1.000\n",
      "            76          -0.01837        1.000\n",
      "            77          -0.01814        1.000\n",
      "            78          -0.01790        1.000\n",
      "            79          -0.01768        1.000\n",
      "            80          -0.01746        1.000\n",
      "            81          -0.01724        1.000\n",
      "            82          -0.01704        1.000\n",
      "            83          -0.01683        1.000\n",
      "            84          -0.01663        1.000\n",
      "            85          -0.01644        1.000\n",
      "            86          -0.01625        1.000\n",
      "            87          -0.01606        1.000\n",
      "            88          -0.01588        1.000\n",
      "            89          -0.01570        1.000\n",
      "            90          -0.01553        1.000\n",
      "            91          -0.01536        1.000\n",
      "            92          -0.01519        1.000\n",
      "            93          -0.01503        1.000\n",
      "            94          -0.01487        1.000\n",
      "            95          -0.01472        1.000\n",
      "            96          -0.01457        1.000\n",
      "            97          -0.01442        1.000\n",
      "            98          -0.01427        1.000\n",
      "            99          -0.01413        1.000\n",
      "         Final          -0.01399        1.000\n"
     ]
    }
   ],
   "source": [
    "# Example training data for custom NER model (using BIO format)\n",
    "training_data = [\n",
    "    ([\"Mero\", \"iPhone\", \"13\", \"Rs\", \"90,000\", \"ma\", \"cha\"], [\"O\", \"B-Product\", \"I-Product\", \"B-Price\", \"I-Price\", \"O\", \"O\"]),\n",
    "    ([\"Nike\", \"ko\", \"juto\", \"haru\", \"Rs\", \"3,000\", \"ma\"], [\"B-Brand\", \"O\", \"B-Product\", \"O\", \"B-Price\", \"I-Price\", \"O\"]),\n",
    "    # Add more training samples...\n",
    "]\n",
    "\n",
    "# Extract features (word, POS tag, previous/next word, etc.)\n",
    "def extract_features(sentence, index):\n",
    "    word = sentence[index]\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'is_capitalized': word[0].isupper(),\n",
    "        'previous_word': sentence[index-1] if index > 0 else None,\n",
    "        'next_word': sentence[index+1] if index < len(sentence)-1 else None,\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Create feature sets\n",
    "featuresets = [(extract_features(sentence, i), label) for sentence, labels in training_data for i, (word, label) in enumerate(zip(sentence, labels))]\n",
    "\n",
    "# Train a classifier (e.g., Maximum Entropy classifier)\n",
    "from nltk.classify import MaxentClassifier\n",
    "classifier = MaxentClassifier.train(featuresets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ecommerce_ner_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mero: O\n",
      "iPhone: B-Product\n",
      "14: I-Product\n",
      "Rs: B-Price\n",
      "100,000: I-Price\n",
      "ma: O\n",
      "cha: O\n"
     ]
    }
   ],
   "source": [
    "with open('ecommerce_ner_classifier.pkl', 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "# Example test sentence\n",
    "test_sentence = [\"Mero\", \"iPhone\", \"14\", \"Rs\", \"100,000\", \"ma\", \"cha\"]\n",
    "\n",
    "# Predict labels for each word in the test sentence\n",
    "for i, word in enumerate(test_sentence):\n",
    "    features = extract_features(test_sentence, i)\n",
    "    predicted_label = classifier.classify(features)\n",
    "    print(f\"{word}: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redmi: O\n",
      "Note9: B-Price\n",
      "Pro: B-Brand\n",
      "ko: O\n",
      "price: B-Product\n",
      "kati: O\n",
      "ho: O\n"
     ]
    }
   ],
   "source": [
    "# Example test sentence\n",
    "test_sentence = [\"Redmi\", \"Note9\", \"Pro\", \"ko\", \"price\", \"kati\", \"ho\"]\n",
    "\n",
    "# Predict labels for each word in the test sentence\n",
    "for i, word in enumerate(test_sentence):\n",
    "    features = extract_features(test_sentence, i)\n",
    "    predicted_label = classifier.classify(features)\n",
    "    print(f\"{word}: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
