# Natural Language Processing

Natural Language Processing is a machine learning technology that gives computers the ability to interpret manipulate and comprehend human language.

![Natural Language Processing Image](./Images/natural_language_processing.png)

# What this repository contains

This repository contains several concepts for Natural Langage Processing and common task solved using different NLP techniques and tools with Deep Learning.

### [Building Chatbots](./Chatbots/)

Building different kinds of chatbot like **rule based chatbot**, **intent based chatbot**, **slot filling chatbot**, **generative chatbot** and **Modern RAG based chatbot**.

- [Simple Chatbot: similarity based and rule based](./Chatbots/Understanding%20Chatbots/)

### [Text Classification](./Classification/)

Text classification using different Machine Learning Technique like traditional machine learning algorith, MLP, RNNs and modern Transformer based model like BERT.

- [Atis Intent Classification MLP](./Classification/ATIS%20intent%20classification/)
- [Simple Binary Classification Example](./Classification/binary_classification.ipynb)

### [LSTM Neural Network Architecture](./LSTM/)

Using LSTM network for different task e.g language modeling, text classification, question answering, summarization.

- [Binary Classification `Many to One`: Tensorflow LSTM](./LSTM/binary_text_classification.ipynb)
- [English to Roman Nepali Translation Word Level `Encoder Decoder`: Tensorflow](./LSTM/eng_roman_translation.ipynb)
- [English to French Character Level Translation `Encoder Decoder`:](./LSTM/eng_to_french_character_level.ipynb)
- [Next word prediction LSTM `Many to One`: Tensorflow](./LSTM/next_word_predictor.ipynb)
- [Next word prediction LSTM 2 `Many to One`: Tensorflow](./LSTM/next_word_predictor.ipynb)
- [Math Text Addition LSTM `Many to Many`: Tensorflow](./LSTM/seq2seq_math_summation.ipynb)

### [NLP with NLTK library](./NLTK/)

Library for text processing.

### [Sequence to Sequence Learning](./Seq%20to%20Seq/)

Sequence to Sequence Learning for different variable length sequential task.

- [Sequence to Sequence LSTM for Reverse Number `Many to Many`: Tensorflow](./Seq%20to%20Seq/01_using_LSTM.ipynb)
- [Encoder Decoder Architecture for Reverse Number: Tensorflow](./Seq%20to%20Seq/02_Encoder_Decoder.ipynb)

### [Text Representation](./Text%20Representation/)

Different text representation techniques like bow, embedding, one hot encoding, tfidf, etc.

- [Bag of Words](./Text%20Representation/bag_of_words.ipynb)
- [N-Grams](./Text%20Representation/n_grams.ipynb)
- [One Hot Encoding](./Text%20Representation/one_hot_encoding.ipynb)
- [Tf-Idf](./Text%20Representation/tf_idf.ipynb)
- [Word Embedding: Word2Vec](./Text%20Representation/word_embedding.ipynb)
