{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(\n",
    "    num_embeddings=1000,\n",
    "    embedding_dim=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.LongTensor(\n",
    "    [1,2,3,4,5]\n",
    ")\n",
    "\n",
    "embedded = embedding_layer(\n",
    "    input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.8806, -1.5844,  1.1348, -0.3444,  0.5277,  1.8012, -0.0129, -0.3972,\n",
       "         -0.2871, -1.0802],\n",
       "        [ 0.3418,  0.6711,  1.8439, -0.6990, -0.6709,  0.1948, -0.2870,  1.5021,\n",
       "         -0.9960, -0.3966]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_2 = nn.Embedding(\n",
    "    num_embeddings=2,\n",
    "    embedding_dim=10\n",
    ")\n",
    "\n",
    "embedding_layer_2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3418,  0.6711,  1.8439, -0.6990, -0.6709,  0.1948, -0.2870,  1.5021,\n",
       "         -0.9960, -0.3966],\n",
       "        [ 0.3418,  0.6711,  1.8439, -0.6990, -0.6709,  0.1948, -0.2870,  1.5021,\n",
       "         -0.9960, -0.3966]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_2(\n",
    "    torch.LongTensor([1,1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8806, -1.5844,  1.1348, -0.3444,  0.5277,  1.8012, -0.0129, -0.3972,\n",
       "         -0.2871, -1.0802],\n",
       "        [ 0.8806, -1.5844,  1.1348, -0.3444,  0.5277,  1.8012, -0.0129, -0.3972,\n",
       "         -0.2871, -1.0802]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_2(\n",
    "    torch.LongTensor([0,0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.tensor([0])) == embedding_layer(torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.arange(0, 1000)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "print(embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_scalar = np.array([1])\n",
    "input_vector = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer_tf = Embedding(\n",
    "    input_dim=2,\n",
    "    output_dim=10\n",
    ")\n",
    "\n",
    "embedded_tf = embedding_layer_tf(\n",
    "    input_scalar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_tf.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.0254395 ,  0.04405124,  0.03798921,  0.01667234, -0.005647  ,\n",
       "        -0.02411038,  0.01450798,  0.00846   ,  0.02556993, -0.04371597],\n",
       "       [ 0.0254395 ,  0.04405124,  0.03798921,  0.01667234, -0.005647  ,\n",
       "        -0.02411038,  0.01450798,  0.00846   ,  0.02556993, -0.04371597]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_tf(\n",
    "    np.asarray([0,0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.0483496 ,  0.03880994,  0.03461048,  0.04239995,  0.03572866,\n",
       "         0.04875128,  0.01053724,  0.03739781, -0.00279566, -0.04985597],\n",
       "       [-0.0483496 ,  0.03880994,  0.03461048,  0.04239995,  0.03572866,\n",
       "         0.04875128,  0.01053724,  0.03739781, -0.00279566, -0.04985597]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_tf(\n",
    "    np.asarray([1,1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.0254395 ,  0.04405124,  0.03798921,  0.01667234, -0.005647  ,\n",
       "        -0.02411038,  0.01450798,  0.00846   ,  0.02556993, -0.04371597],\n",
       "       [-0.0483496 ,  0.03880994,  0.03461048,  0.04239995,  0.03572866,\n",
       "         0.04875128,  0.01053724,  0.03739781, -0.00279566, -0.04985597]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_tf(\n",
    "    # np.asarray([2]) error because no mapping for 2 in 2 dim embedding layer\n",
    "    # np.asarray([0,1,2]) error because no mapping for 3 input in 2 dim embedding\n",
    "    np.asarray([0,1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram\n",
    "- Skip gram model predicts surrounding words based on the context words based on the target word\n",
    "- by predicting context word skip gram efficiently learns meaningful word representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'cat', 'sat', 'on', 'the', 'mat']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The cat sat on the mat\"\n",
    "tokens = text.lower().split(\" \")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['cat', 'sat', 'on'], Target: the\n",
      "Context: ['the', 'sat', 'on', 'the'], Target: cat\n",
      "Context: ['the', 'cat', 'on', 'the', 'mat'], Target: sat\n",
      "Context: ['the', 'cat', 'sat', 'the', 'mat'], Target: on\n",
      "Context: ['cat', 'sat', 'on', 'mat'], Target: the\n",
      "Context: ['sat', 'on', 'the'], Target: mat\n"
     ]
    }
   ],
   "source": [
    "window_size = 3\n",
    "context = []\n",
    "target = []\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    start = max(0, i - window_size)\n",
    "    end = min(len(tokens), i + window_size + 1)\n",
    "    context.append(\n",
    "        tokens[start:i] + tokens[i+1:end]\n",
    "    )\n",
    "    target.append(tokens[i])\n",
    "\n",
    "for c, t in zip(context, target):\n",
    "    print(f\"Context: {c}, Target: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 'the'),\n",
       " ('sat', 'the'),\n",
       " ('on', 'the'),\n",
       " ('the', 'cat'),\n",
       " ('sat', 'cat'),\n",
       " ('on', 'cat'),\n",
       " ('the', 'cat'),\n",
       " ('the', 'sat'),\n",
       " ('cat', 'sat'),\n",
       " ('on', 'sat'),\n",
       " ('the', 'sat'),\n",
       " ('mat', 'sat'),\n",
       " ('the', 'on'),\n",
       " ('cat', 'on'),\n",
       " ('sat', 'on'),\n",
       " ('the', 'on'),\n",
       " ('mat', 'on'),\n",
       " ('cat', 'the'),\n",
       " ('sat', 'the'),\n",
       " ('on', 'the'),\n",
       " ('mat', 'the'),\n",
       " ('sat', 'mat'),\n",
       " ('on', 'mat'),\n",
       " ('the', 'mat')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_pairs = list()\n",
    "\n",
    "for c, t in zip(context, target):\n",
    "    for word in c:\n",
    "        generated_pairs.append((word, t))\n",
    "        \n",
    "generated_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_text(\"./word_embedding_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there 123 ZZab 123 '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"[^a-zA-Z0-9]+\", ' ', \"Hello there @ 123 , . -\\n)()ZZab 123@#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 6), ('e', 4)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(\"aaabbccedeeedaffaa\")\n",
    "\n",
    "c.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'cat': 3, 'dog': 1, 'mat': 1, 'sat': 1})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = Counter([\"cat\", \"cat\", \"dog\", \"mat\", \"sat\", \"cat\"])\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a', 'b', 'c', 'e', 'd', 'f'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([6, 2, 2, 4, 2, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(words: list) -> tuple:\n",
    "    \"\"\"Build the vocabulary and the index to word dict from the words\n",
    "    \n",
    "    arguments:\n",
    "        - words: list of words\n",
    "    returns:\n",
    "        - vocabulary: dict\n",
    "        - idx_word: dict    \n",
    "    \"\"\"\n",
    "    word_counts = Counter(words)\n",
    "    vocabulary = {word: idx for idx, (word, _count) in enumerate(word_counts.items())}\n",
    "    idx_word = {idx: word for word, idx in vocabulary.items()}\n",
    "    return vocabulary, idx_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cat': 0, 'dog': 1, 'mat': 2, 'sat': 3},\n",
       " {0: 'cat', 1: 'dog', 2: 'mat', 3: 'sat'})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_vocabulary([\"cat\", \"cat\", \"dog\", \"mat\", \"sat\", \"cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "-1\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(-2, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(words: list, vocabulary: dict, window_size=2):\n",
    "    data = []\n",
    "    pair = []\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        for neighbor in range(-window_size, window_size + 1):\n",
    "            if neighbor == 0:\n",
    "                continue\n",
    "            n_idx  = i + neighbor\n",
    "            if 0 <= n_idx < len(words):\n",
    "                data.append((vocabulary[word], vocabulary[words[n_idx]]))\n",
    "                pair.append((word, words[n_idx]))\n",
    "                \n",
    "    return data, pair\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, p = prepare_data([\"cat\", \"and\", \"dog\", \"sat\", \"mat\"], {\"cat\": 0, \"dog\": 1, \"mat\": 2, \"sat\": 3, \"and\": 4}, window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 'and'),\n",
       " ('cat', 'dog'),\n",
       " ('and', 'cat'),\n",
       " ('and', 'dog'),\n",
       " ('and', 'sat'),\n",
       " ('dog', 'cat'),\n",
       " ('dog', 'and'),\n",
       " ('dog', 'sat'),\n",
       " ('dog', 'mat'),\n",
       " ('sat', 'and'),\n",
       " ('sat', 'dog'),\n",
       " ('sat', 'mat'),\n",
       " ('mat', 'dog'),\n",
       " ('mat', 'sat')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skipgram(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(skipgram, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.output_layer = torch.nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, center_word):\n",
    "        embedded = self.embeddings(center_word) # [center, ...] 32\n",
    "        o = self.output_layer(embedded)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 35])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = skipgram(35, 10)\n",
    "test_model = test_model(\n",
    "    # torch.arange(0,36) error because we have 35 words in voabulary\n",
    "    # torch.arange(0, 32) # for 32 dim input tensor output: [32, 35] that means 32 words with each 35 embedding\n",
    "    # torch.tensor([0]) # [1, 35] that means 1 word embedding\n",
    "    # torch.tensor([35]) # error because no mapping for 36 in 35 embedding layer\n",
    "    torch.tensor([0, 34])\n",
    ")\n",
    "test_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8], [9, 0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ = [1,2,3,4,5,6,7,8,9,0]\n",
    "[data_[i:i+2] for i in range(0, len(data_), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, batch_size):\n",
    "    np.random.shuffle(data)\n",
    "    n_batches = len(data) // batch_size\n",
    "    batches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(skip_gram_model, data, vocab_size, embedding_dim, batch_size=32, epochs=10, learning_r=0.01):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(skip_gram_model.parameters(), lr=learning_r)\n",
    "    \n",
    "    skip_gram_model.to(device)\n",
    "    \n",
    "    batches = create_batches(data, batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in batches:\n",
    "            # a batch contains [(center, context), ...]\n",
    "            center_batch = [pair[0] for pair in batch] # 32 center words\n",
    "            context_batch = [pair[1] for pair in batch] # 32 context words\n",
    "                        \n",
    "            center_batch = torch.tensor(center_batch).to(device)\n",
    "            context_batch = torch.tensor(context_batch).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = skip_gram_model(center_batch)\n",
    "            # compute loss\n",
    "            loss = criterion(output, context_batch)\n",
    "            \n",
    "            total_loss = total_loss + loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "            print(f\"epoch {epoch} loss {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sat on the mat.\n",
      "The dog lay on the rug.\n",
      "The cat chased the rat.\n",
      "The dog barked at the cat.\n",
      "The mat was next to the rug.\n",
      "The dog and the cat slept together on the mat.\n",
      "The mat and the rug were dirty.\n",
      "The tree is in the backyard.\n",
      "The bird flew over the trees.\n",
      "The bird sang in the tree.\n",
      "The bird liked to play near the tree.\n",
      "The tree was tall and the bird liked to sit on it.\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, idx_word = build_vocabulary(words)\n",
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = {\n",
    "    \"a\": 0,\n",
    "    \"b\": 1\n",
    "}\n",
    "\n",
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocabulary: 35\n"
     ]
    }
   ],
   "source": [
    "print(f\"size of vocabulary: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'cat': 1,\n",
       " 'sat': 2,\n",
       " 'on': 3,\n",
       " 'mat': 4,\n",
       " 'dog': 5,\n",
       " 'lay': 6,\n",
       " 'rug': 7,\n",
       " 'chased': 8,\n",
       " 'rat': 9,\n",
       " 'barked': 10,\n",
       " 'at': 11,\n",
       " 'was': 12,\n",
       " 'next': 13,\n",
       " 'to': 14,\n",
       " 'and': 15,\n",
       " 'slept': 16,\n",
       " 'together': 17,\n",
       " 'were': 18,\n",
       " 'dirty': 19,\n",
       " 'tree': 20,\n",
       " 'is': 21,\n",
       " 'in': 22,\n",
       " 'backyard': 23,\n",
       " 'bird': 24,\n",
       " 'flew': 25,\n",
       " 'over': 26,\n",
       " 'trees': 27,\n",
       " 'sang': 28,\n",
       " 'liked': 29,\n",
       " 'play': 30,\n",
       " 'near': 31,\n",
       " 'tall': 32,\n",
       " 'sit': 33,\n",
       " 'it': 34}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 1),\n",
       "  (0, 2),\n",
       "  (0, 3),\n",
       "  (1, 0),\n",
       "  (1, 2),\n",
       "  (1, 3),\n",
       "  (1, 0),\n",
       "  (2, 0),\n",
       "  (2, 1),\n",
       "  (2, 3)],\n",
       " [('the', 'cat'),\n",
       "  ('the', 'sat'),\n",
       "  ('the', 'on'),\n",
       "  ('cat', 'the'),\n",
       "  ('cat', 'sat'),\n",
       "  ('cat', 'on'),\n",
       "  ('cat', 'the'),\n",
       "  ('sat', 'the'),\n",
       "  ('sat', 'cat'),\n",
       "  ('sat', 'on')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, pair = prepare_data(words, vocabulary, window_size=3)\n",
    "\n",
    "data[:10], pair[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 10\n",
    "s_g = skipgram(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skipgram(\n",
       "  (embeddings): Embedding(35, 10)\n",
       "  (output_layer): Linear(in_features=10, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 59.02077603340149\n",
      "epoch 100 loss 37.434876680374146\n",
      "epoch 200 loss 37.119945764541626\n",
      "epoch 300 loss 37.02324199676514\n",
      "epoch 400 loss 36.98068046569824\n",
      "epoch 500 loss 36.95994019508362\n",
      "epoch 600 loss 36.947999238967896\n",
      "epoch 700 loss 36.94011187553406\n",
      "epoch 800 loss 36.9343466758728\n",
      "epoch 900 loss 36.92980980873108\n",
      "epoch 999 loss 36.9260835647583\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train(s_g, data, vocab_size, embedding_dim, batch_size=batch_size, epochs=1000, learning_r=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skipgram(\n",
       "  (embeddings): Embedding(35, 10)\n",
       "  (output_layer): Linear(in_features=10, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_g.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = s_g.embeddings.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27078   ,  0.37476772, -0.49283603,  0.24214666, -0.607796  ,\n",
       "       -0.11571923, -0.25166234,  0.00823486, -0.25608203,  0.46546626],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.3293637e-01,  1.8461654e+00, -8.9689320e-01, -1.9493051e+00,\n",
       "       -1.5913031e+00,  2.8027799e+00, -3.6414716e-01,  5.9100613e-04,\n",
       "        5.3977050e-02, -1.1853317e+00], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : embedding :[-0.27078     0.37476772 -0.49283603  0.24214666 -0.607796   -0.11571923\n",
      " -0.25166234  0.00823486 -0.25608203  0.46546626]\n",
      "cat : embedding :[ 9.3293637e-01  1.8461654e+00 -8.9689320e-01 -1.9493051e+00\n",
      " -1.5913031e+00  2.8027799e+00 -3.6414716e-01  5.9100613e-04\n",
      "  5.3977050e-02 -1.1853317e+00]\n",
      "sat : embedding :[ 1.9124764  2.4179773 -0.8639681  0.6720566 -0.8368558  0.2094313\n",
      "  1.6879451 -1.8529346  3.0814295 -2.0283315]\n",
      "on : embedding :[ 3.288054   -1.228685   -0.10843354  0.97753805 -0.6301892   0.03767175\n",
      "  0.99255556  0.6451838   1.2749192  -2.084796  ]\n",
      "mat : embedding :[ 0.9762366   1.854475   -3.2215302   0.75082767 -0.01865999  0.5520588\n",
      " -1.1162462  -0.46379152  0.72042286 -0.11134949]\n",
      "dog : embedding :[-0.45078906  1.1658604  -1.8016922  -0.63098025  0.10263806  1.6203414\n",
      "  0.18846387 -0.39020047  3.33304    -3.473504  ]\n",
      "lay : embedding :[ 1.7678895   2.0032725  -2.283633   -1.4169966  -1.0540261   0.5823018\n",
      "  0.77960765  0.36290362  3.2042189   2.0227702 ]\n",
      "rug : embedding :[ 0.09127849  0.07267509 -3.6898623  -1.1081237   1.1750357  -1.8782548\n",
      "  2.786162   -1.2546678   1.7273575   0.36970466]\n",
      "chased : embedding :[-0.09259927 -3.5553966  -1.3290851   0.5501675  -2.2310433   2.4469435\n",
      "  0.9990951  -1.3958555   1.8064153  -3.3236923 ]\n",
      "rat : embedding :[-1.0412172   0.9424851  -1.7464502  -1.8473811  -4.2900014   0.18297856\n",
      "  1.6686671  -2.0267057   0.7536655  -1.0960389 ]\n",
      "barked : embedding :[ 0.25917697 -2.4066415  -1.4581708  -1.7576128  -3.0347033  -0.2547327\n",
      "  2.1927948   0.072846    1.745644   -3.7072442 ]\n",
      "at : embedding :[-0.4887824   0.6619602  -1.909085   -0.7936858  -4.612713   -0.9709135\n",
      " -0.72623664 -1.007583    1.0221584  -1.8070441 ]\n",
      "was : embedding :[ 2.1780787   0.24973714 -2.1280177   1.9715354   0.855096    0.6828534\n",
      "  1.5182421  -3.4426713  -0.06852461  0.5608065 ]\n",
      "next : embedding :[ 4.332634   1.8556422 -0.6691481  1.4488125 -0.5033614  1.9363856\n",
      " -0.4419658 -0.9591766  2.3282988  3.1801343]\n",
      "to : embedding :[-0.5110353   1.0678118   2.4208484  -0.52767986  0.74447     0.9514588\n",
      "  0.13636114 -0.7866552   4.451315    0.66402215]\n",
      "and : embedding :[ 0.8723338  -0.44892243  0.8361479   1.2906493  -3.0450983   1.0773617\n",
      "  1.0087746  -1.2334762   0.46479803  2.038643  ]\n",
      "slept : embedding :[ 2.8121269   1.4945016  -1.0725838  -0.69225895 -0.07007857 -1.7540714\n",
      "  1.4433125  -2.347631   -0.5921134  -4.058099  ]\n",
      "together : embedding :[ 2.7575612  1.7559601  1.6099117  0.5194619 -1.6796515  0.4013672\n",
      "  1.8533502 -1.4640881  1.637404  -2.4127183]\n",
      "were : embedding :[ 0.99722385 -4.2632346  -3.5953188  -1.1249288   1.4460338   1.6087397\n",
      "  1.7470496  -1.767814   -0.29147002  0.2917989 ]\n",
      "dirty : embedding :[ 0.40920064 -3.7289941  -1.8035403   0.78175133 -1.5289962   0.18969272\n",
      "  0.08216908 -1.802253    1.4768338   3.7429318 ]\n",
      "tree : embedding :[-1.8598975  -1.0538499   1.6055341  -0.13564408 -0.404862    0.450984\n",
      " -0.9707481  -3.5027595   0.01385279  0.8463074 ]\n",
      "is : embedding :[ 0.59061664 -1.5576663  -2.8195798  -0.01103513 -0.61370146 -2.3668313\n",
      " -3.075114   -2.8640096  -1.1190511   0.930847  ]\n",
      "in : embedding :[ 0.2524452  -2.3238919  -0.6465702  -3.2973864  -1.5560439  -0.35773352\n",
      " -1.4712083  -1.7421336  -0.04577119  4.0936418 ]\n",
      "backyard : embedding :[-0.30970925 -1.445874    0.13886455 -0.31910297 -2.2175567  -1.743459\n",
      " -3.264688   -0.29041326  2.467426    1.1583799 ]\n",
      "bird : embedding :[ 1.4560905  -1.8360368   0.0309262  -0.11437366  1.851902    0.88489825\n",
      " -3.6789606  -1.1917629  -0.35573676 -0.16044667]\n",
      "flew : embedding :[ 1.8226337  -0.42891067 -0.11786804 -4.0741615  -3.4364462   0.03401819\n",
      " -3.2789366  -0.6610659  -2.0770679   0.1757088 ]\n",
      "over : embedding :[ 3.291679   -2.5545468   1.234526   -2.824037   -1.3403006  -1.0585539\n",
      " -2.738212    0.89669704  0.81081027  0.03498469]\n",
      "trees : embedding :[-0.4453141  -0.3987998   0.07770812 -4.939025   -1.2079034   0.00929504\n",
      " -3.8374476  -0.04458584  0.7459012  -0.15105575]\n",
      "sang : embedding :[ 2.210932   -1.8828984   1.683477   -0.7023504  -1.2196146  -2.4845004\n",
      " -3.5109634  -2.3365164  -0.87049454  0.3240199 ]\n",
      "liked : embedding :[ 1.144238    0.51977444  1.4249284  -2.15461     1.8341231  -1.6938475\n",
      "  0.39097753 -1.8457628   0.03334182  0.6645427 ]\n",
      "play : embedding :[ 1.8243604  -1.2299205   1.7053555   0.13940708  0.14040364 -3.24242\n",
      "  0.9438991  -1.6143999   1.5683483   1.6707455 ]\n",
      "near : embedding :[ 1.2953892  -1.5590205   0.3287635   0.70150745  1.831387   -0.60528284\n",
      " -1.4615542  -2.7427845   1.2812123   2.210813  ]\n",
      "tall : embedding :[ 0.85091615  1.784628    1.3091964  -1.775547   -0.773352   -0.8741829\n",
      " -1.1315955  -3.9916527  -1.9355464   0.38377184]\n",
      "sit : embedding :[ 1.8050439   1.3515779   2.7311065   0.7529956   0.2734621  -1.6928802\n",
      "  0.15775564  1.9713795   1.1896      1.2553445 ]\n",
      "it : embedding :[ 3.3318992   1.7007751   1.8389446  -1.5596517   2.5176725   0.22237614\n",
      "  2.1645722   0.56269705 -0.0649415   1.1619312 ]\n",
      "The size of embeddings:\n",
      "(35, 10)\n"
     ]
    }
   ],
   "source": [
    "for word, idx in vocabulary.items():\n",
    "    print(f\"{word} : embedding :{word_embeddings[idx]}\")\n",
    "    \n",
    "print(f\"The size of embeddings:\")\n",
    "print(word_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"cat sat\"\n",
    "tokens = tokenize(text)\n",
    "idxs = [vocabulary[token] for token in tokens]\n",
    "idxs = torch.tensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_idxs = s_g.embeddings(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_idxs_2 = word_embeddings[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_idxs.shape == embedded_idxs_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.tril(np.ones((3,3)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 1., 0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 0., 0.]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[[0,1,0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(word1, word2, embeddings=word_embeddings):\n",
    "    idx1 = vocabulary[word1]\n",
    "    idx2 = vocabulary[word2]\n",
    "    \n",
    "    embedding1 = embeddings[idx1]\n",
    "    embedding2 = embeddings[idx2]\n",
    "    \n",
    "    dot_product = np.abs(np.dot(embedding1, np.transpose(embedding2)))\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    \n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity_2(word: str, words: list, embeddings=word_embeddings) -> list:\n",
    "    idx = vocabulary[word]\n",
    "    idxs = [vocabulary[w] for w in words]\n",
    "    \n",
    "    embedding = embeddings[idx] # [1, 10]\n",
    "    embedding_idxs = embeddings[idxs] # [n, 10]\n",
    "    \n",
    "    similarities = list()\n",
    "    \n",
    "    for e in embedding_idxs:\n",
    "        dot_product = np.abs(np.dot(embedding, np.transpose(e)))\n",
    "        n1 = np.linalg.norm(embedding)\n",
    "        n2 = np.linalg.norm(e)\n",
    "        s = dot_product / (n1 * n2)\n",
    "        similarities.append(s)\n",
    "        \n",
    "    return similarities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 28)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([[1,2,3], [1,2,3],[9,8,1]])\n",
    "\n",
    "dot_1 = np.dot(a, b[0].T)\n",
    "dot_2 = np.dot(a, b[1].T)\n",
    "dot_3 = np.dot(a, b[2].T)\n",
    "\n",
    "dot_1, dot_2, dot_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [9, 8, 1]]),\n",
       " array([[1, 1, 9],\n",
       "        [2, 2, 8],\n",
       "        [3, 3, 1]]),\n",
       " array([1, 2, 3]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, b.T, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_4 = np.dot(a, b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 28])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5]), 5)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot([1,2],[[1],[2]]), np.dot([1,2], [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between cat and dog is 0.5173586010932922\n",
      "similarity between dog and sat is 0.6939213871955872\n",
      "similarity between tree and cat is 0.17029790580272675\n",
      "similarity between sat and mat is 0.4760937988758087\n",
      "similarity between cat and tree is 0.17029790580272675\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    [\"cat\", \"dog\"],\n",
    "    [\"dog\", \"sat\"],\n",
    "    [\"tree\", \"cat\"],\n",
    "    [\"sat\", \"mat\"],\n",
    "    [\"cat\", \"tree\"]\n",
    "]\n",
    "\n",
    "for word1, word2 in pairs:\n",
    "    sim = compute_cosine_similarity(word1, word2)\n",
    "    print(f\"similarity between {word1} and {word2} is {sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5173586, 0.1702979]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine_similarity_2(\"cat\", [\"dog\", \"tree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similar(word: str, words: list, embeddings=word_embeddings):\n",
    "    idx = vocabulary[word]\n",
    "    idxs = [vocabulary[w] for w in words]\n",
    "    \n",
    "    embedding_idx = embeddings[idx]\n",
    "    embedding_idxs = embeddings[idxs]\n",
    "    \n",
    "    dot_product = np.abs(np.dot(embedding_idx, np.transpose(embedding_idxs))) # [1, 10].[10, n] = [1, n]\n",
    "    norm1 = np.linalg.norm(embedding_idx) # [1, 10] -> [1]\n",
    "    norm2 = np.linalg.norm(embedding_idxs, axis=1) # [n, 10] -> [n]\n",
    "    \n",
    "    similarities = dot_product / (norm1 * norm2) # [1, n] / ([1] * [n]) -> [1, n]\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.23606798, 5.        ])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array([[1,2],[3,4]]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5173586 , 0.17029792], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine_similar(\"cat\", [\"dog\", \"tree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5 ,  0.25])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1]) / (np.array([2]) * np.array([-1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 0.25)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (2 * -1), 1 / (2 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 86])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot([6,4],[[4,9],[9,8]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
